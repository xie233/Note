

## HDFS
HDFS 是 Hadoop 计算平台的底层分布式文件系统(Hadoop Distributed File System)，整体架构：
Name Node +多个 Data Node 组成，其中 Name Node 存在单点故障，同时分配备份节点 Secondary Name Node。
元数据存储在 Name Node 内存中，其中文件分块存储（每个块 64MB 大小），不适合小文件存储，随着文件数量增多，
元数据信息大小可能会超过单机的内存。

客户端写数据过程：
1. client 向 Name Node 发起写文件请求
2. Name Node 确认文件不存在，在命名空间里添加新文件信息，授权 client 写文件，返回三个 Data Node 地址（三个副本）
3. client 对文件分块，发送文件块给 Data Node
4. Data Node 写入完成后，块的同步，复制给 Data Node2 和 Data Node3 
5. 文件传输完成， client 通知 Name Node

客户端读数据过程：
1. client 向 Name Node 发起读文件请求
2. Name Node 查询数据块的映射，返回 Data Node 的地址
3. client 请求 Data Node 的数据，直到完成（文件完整校验）

##### 元数据
检查点技术，fsimage 快照快速恢复元数据， edits log 补充最新的操作日志
##### 多副本
考虑单点故障，每个数据块保存多个副本
##### 心跳
Name Node 并不持久化块的位置信息，通过心跳向 Data Node 获取块信息，简化了 Data Node 频繁的添加与移除带来的管理成本


## TFS
TFS 是淘宝内部使用的文件系统，考虑到小文件存储需求较大，在 HDFS 上做了一些优化。 TFS 以 Block 为单位多副本，每个 Block 由大量小文件组成，每个 Block 有唯一的 blockid，采用了与 HDFS 类似的主从架构。

客户端写数据过程：
1. client 向 Name Server 发起写文件请求
2. Name Node 负载均衡，选择一个合适的 Block， 返回 blockid 的 Data Server 列表给 client
3. client 选择 master Data Server 写入， master Data Server 再同步副本
4. 所有 Data Server 写入成功， master 向 Name Server 提交写请求
5. Name Server 更新 Block 版本
6. master 返回结果给 client


客户端读数据过程：
1. client 根据文件名解析 blockid 和 fileid，请求 Name Server
2. Name Node 查询所在的 Data Node，返回
3. client 根据 blockid 和 fileid 向 Data Node 请求读数据

## Dynamo
Dynamo 是亚马逊自研的去中心化分布式键值存储系统，通过一致性哈希算法直接定位 data 应该分布在哪一个 Data Node 上，并通过增加虚拟节点，平衡每个节点的数据分布，在多副本下数据一致性难以保证，采用 NWR 模型，只要满足 W+R>N

